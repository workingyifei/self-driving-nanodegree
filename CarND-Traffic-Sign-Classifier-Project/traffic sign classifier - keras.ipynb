{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras to classify traffic signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifei/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import some packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 393,989\n",
      "Trainable params: 393,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "# Multi layer feedforward neural network \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu') )\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickled data\n",
    "with open('./small_traffic_set/small_train_traffic.p', mode = 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, y_train = data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 0s - loss: 1.3048 - acc: 0.3375 - val_loss: 0.7272 - val_acc: 0.6500\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s - loss: 0.9602 - acc: 0.5875 - val_loss: 0.5543 - val_acc: 0.9500\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s - loss: 0.6335 - acc: 0.7125 - val_loss: 0.4950 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s - loss: 0.6972 - acc: 0.6750 - val_loss: 0.3520 - val_acc: 0.8500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s - loss: 0.5042 - acc: 0.7750 - val_loss: 0.3397 - val_acc: 0.8500\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s - loss: 0.4989 - acc: 0.7750 - val_loss: 0.2439 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s - loss: 0.3672 - acc: 0.8875 - val_loss: 0.2209 - val_acc: 0.8500\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s - loss: 0.3780 - acc: 0.8250 - val_loss: 0.1979 - val_acc: 0.8500\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s - loss: 0.3180 - acc: 0.8875 - val_loss: 0.1741 - val_acc: 0.9500\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s - loss: 0.3150 - acc: 0.8500 - val_loss: 0.1426 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X_normalized = np.array(X_train / 255.0 - 0.5)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional model\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 0s - loss: 1.3733 - acc: 0.3125 - val_loss: 0.9004 - val_acc: 0.4500\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s - loss: 0.9827 - acc: 0.4000 - val_loss: 0.6315 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s - loss: 0.8812 - acc: 0.6500 - val_loss: 0.4799 - val_acc: 0.8500\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s - loss: 0.5633 - acc: 0.8250 - val_loss: 0.4040 - val_acc: 0.8500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s - loss: 0.6342 - acc: 0.7000 - val_loss: 0.3077 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s - loss: 0.5579 - acc: 0.8000 - val_loss: 0.2488 - val_acc: 0.8500\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s - loss: 0.3873 - acc: 0.8625 - val_loss: 0.2331 - val_acc: 0.8500\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s - loss: 0.4016 - acc: 0.8375 - val_loss: 0.2080 - val_acc: 0.8500\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s - loss: 0.3237 - acc: 0.8125 - val_loss: 0.1933 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s - loss: 0.3143 - acc: 0.8250 - val_loss: 0.1781 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# load pickled data\n",
    "with open('./../CarND-Traffic-Sign-Classifier-Project/small_traffic_set/small_train_traffic.p', mode = 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# split data\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "20/20 [==============================] - 0s\n",
      "loss: 0.3124326765537262\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate model against the test data\n",
    "with open('./small_traffic_set/small_test_traffic.p', mode = 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
